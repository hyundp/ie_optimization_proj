{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    \\n    더 나아가서,\\n    1. multi agent를 사용해야하나?\\n    \\n    state 설정\\n    만약 넣은 state가 100,None,2,1,0,0(defalut) 라면, action value는 \\n    3^6=729개의 조합에 대해 q-value를 뽑고 그 중 하나를 고르는 것.\\n    따라서 state는 (729, 6)의 크기를 갖는다.\\n    \\n    deep q 이유\\n    만약 일반 q learning을 쓸 때, \\n    하나의 하이퍼파라미터 당 10개의 tracking을 한다고 가정하면, 10^6만큼의 q-table이 필요하게 된다.\\n    따라서 시/공간 효율성을 위해 하이퍼파라미터 조합에 대한 q-value 값을 표현해주는 신경망을 학습시키는 것이 도움이 될 수 있다.\\n    \\n    장점\\n    1. 기존 hyperparameter tunning 방식은 내가 가능한 조합을 미리 설계해주어야 했다. 그래서 경험적으로 가능한 조합에 대한 지식이 있어야한다.\\n       하지만 강화학습에서는 step을 통해 조합을 찾으므로 미리 가능한 조합을 설계해둘 필요가 없다.\\n    2. 학습된 모델을 데이터가 추가된 경우에도 그대로 사용할 수 있다.\\n    3. 한번 만들어두면 시간 효율적이다.\\n    4. 학습된 모델을 파인튜닝하여 사용할 수 있다.\\n    5. 기존 방식은 내가 조합을 미리 제한해두기 때문에 최적의 조합인지에 대한 확신을 가지기 어렵다.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    정리\n",
    "    1. agent를 통해서 policy(랜덤값이 앱실론보다 작으면 랜덤 인덱스와 랜덤 action을, \n",
    "                            그렇지 않으면 내부 신경망(LSTM)에 state값을 넣어 \n",
    "                            가능한 모든 action에 대한 action_values(Q_values) 중 가장 큰 값에 해당하는 인덱스와 그 값을 반환한다.\n",
    "                            이때 사용되는 내부 신경망은 main_network이다.)\n",
    "        에 맞는 action_index와 action_value를 찾아낸다.\n",
    "    2. 찾아낸 action_index와 action_value를 env에 넣어서 RF 모델을 돌린 뒤 next_state(다음 action 집합)와 reward(정확도)를 찾아낸다.\n",
    "    3. memory(replay buffer)에 현재 state와 action_index, 그리고 위에서 도출된 next_state, reward를 넣는다.\n",
    "    4. replay buffer에서 원하는 batch size만큼 sample(state, action_index, reward, next_state)을 뽑아낸다.\n",
    "    5. sample의 state를 main_network에 넣어서 도출된 값들 중 action index에 맞는 값을 뽑고 이를 main Q 값으로 한다.\n",
    "    6. sample의 next_state를 target_network에 넣어서 값을 도출한 뒤, 그 중 가장 큰 값을 찾아낸다.\n",
    "    7. 위에서 찾아낸 값을 Q라고 한다면, reward + gamma(discount factor)*Q = target Q로 정한다.\n",
    "    8. mainQ와 targetQ를 loss function에 넣어서 내부 신경망 파라미터를 역전파로 업데이트 한다. 이때 옵티마이저도 사용된다.\n",
    "    9. 이 과정을 반복하여 main Q가 target Q에 가까워질 수 있게 한다.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"    \n",
    "    더 나아가서,\n",
    "    1. multi agent를 사용해야하나?\n",
    "    \n",
    "    state 설정\n",
    "    만약 넣은 state가 100,None,2,1,0,0(defalut) 라면, action value는 \n",
    "    3^6=729개의 조합에 대해 q-value를 뽑고 그 중 하나를 고르는 것.\n",
    "    따라서 state는 (729, 6)의 크기를 갖는다.\n",
    "    \n",
    "    deep q 이유\n",
    "    만약 일반 q learning을 쓸 때, \n",
    "    하나의 하이퍼파라미터 당 10개의 tracking을 한다고 가정하면, 10^6만큼의 q-table이 필요하게 된다.\n",
    "    따라서 시/공간 효율성을 위해 하이퍼파라미터 조합에 대한 q-value 값을 표현해주는 신경망을 학습시키는 것이 도움이 될 수 있다.\n",
    "    \n",
    "    장점\n",
    "    1. 기존 hyperparameter tunning 방식은 내가 가능한 조합을 미리 설계해주어야 했다. 그래서 경험적으로 가능한 조합에 대한 지식이 있어야한다.\n",
    "       하지만 강화학습에서는 step을 통해 조합을 찾으므로 미리 가능한 조합을 설계해둘 필요가 없다.\n",
    "    2. 학습된 모델을 데이터가 추가된 경우에도 그대로 사용할 수 있다.\n",
    "    3. 한번 만들어두면 시간 효율적이다.\n",
    "    4. 학습된 모델을 파인튜닝하여 사용할 수 있다.\n",
    "    5. 기존 방식은 내가 조합을 미리 제한해두기 때문에 최적의 조합인지에 대한 확신을 가지기 어렵다.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque, namedtuple\n",
    "import copy\n",
    "from itertools import product\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "class h2y2_RF_Model():\n",
    "    def __init__(self, cur_hyperparameter):\n",
    "        self.model = RandomForestClassifier(**cur_hyperparameter, random_state=42)\n",
    "        self.data = load_breast_cancer()\n",
    "        x_data = pd.DataFrame(self.data.data, columns=self.data.feature_names)\n",
    "        y_data = self.data.target\n",
    "        self.train_x, self.test_x, self.train_y, self.test_y = train_test_split(x_data, y_data, test_size=0.3, random_state=42)\n",
    "        \n",
    "        \n",
    "    def evaluate(self):\n",
    "        self.model.fit(self.train_x, self.train_y)\n",
    "        predict = self.model.predict(self.test_x)\n",
    "        return accuracy_score(self.test_y, predict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H2Y2_env:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # initial\n",
    "        self.comb_config = [[-50,0,50], [-2,0,2], [-1,0,1], [-1,0,1], [-0.1,0,0.1], [-0.1,0,0.1]]\n",
    "        self.hyperparameter_list = ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'min_weight_fraction_leaf', 'min_impurity_decrease']\n",
    "        self.epsilon = 1e-3\n",
    "    \n",
    "    # 하이퍼파라미터의 범위를 제한해주는 함수 ver1\n",
    "    def check_bound(self, comb):        \n",
    "        comb_sum = comb[1] + comb[2]\n",
    "        if comb[0] == 'n_estimators':\n",
    "            if comb_sum > 0:\n",
    "                return int(comb_sum)\n",
    "        elif comb[0] == 'max_depth':\n",
    "            if comb_sum > 0:\n",
    "                return int(comb_sum)\n",
    "        elif comb[0] == 'min_samples_leaf':\n",
    "            if comb_sum > 0:\n",
    "                return int(comb_sum)\n",
    "        elif comb[0] == 'min_samples_split':\n",
    "            if comb_sum > 1:\n",
    "                return int(comb_sum)\n",
    "        elif comb[0] == 'min_weight_fraction_leaf':\n",
    "            if comb_sum >= 0 and comb_sum <= 0.5:\n",
    "                return float(comb_sum)\n",
    "        elif comb[0] == 'min_impurity_decrease':\n",
    "            if comb_sum >= 0 and comb_sum <= 1:\n",
    "                return float(comb_sum)\n",
    "        return comb[1]\n",
    "    \n",
    "    # 하이퍼파라미터의 범위를 제한해주는 함수 ver2\n",
    "    def check_bound_ver2(self, comb):\n",
    "        sample_state = []\n",
    "        for i in range(len(comb[2])):\n",
    "            comb_sum = comb[1] + comb[2][i]\n",
    "            if comb[0] == 'n_estimators':\n",
    "                if comb_sum > 0:\n",
    "                    sample_state.append(int(comb_sum))\n",
    "            elif comb[0] == 'max_depth':\n",
    "                if comb_sum > 0:\n",
    "                    sample_state.append(int(comb_sum))\n",
    "            elif comb[0] == 'min_samples_leaf':\n",
    "                if comb_sum > 0:\n",
    "                    sample_state.append(int(comb_sum))\n",
    "            elif comb[0] == 'min_samples_split':\n",
    "                if comb_sum > 1:\n",
    "                    sample_state.append(int(comb_sum))\n",
    "            elif comb[0] == 'min_weight_fraction_leaf':\n",
    "                if comb_sum >= 0 and comb_sum <= 0.5:\n",
    "                    sample_state.append(float(comb_sum))\n",
    "            elif comb[0] == 'min_impurity_decrease':\n",
    "                if comb_sum >= 0 and comb_sum <= 1:\n",
    "                    sample_state.append(float(comb_sum))\n",
    "            else:\n",
    "                sample_state.append(comb[1])\n",
    "        return sample_state\n",
    "    \n",
    "    # hyper-parameter vector를 받아서 다음으로 가능한 모든 조합을 반환해주는 함수\n",
    "    def make_state(self, cur_comb):\n",
    "        comb = list(product(*self.comb_config))\n",
    "        state = [tuple(map(self.check_bound, zip(self.hyperparameter_list, cur_comb, tuple_comb))) for tuple_comb in comb]\n",
    "        # print(state)\n",
    "        return state\n",
    "        \n",
    "    # q_value로 도출된 action_index가 어떤 observation을 가리키는지 확인한다.\n",
    "    def mapping_action(self, state, action_index):\n",
    "        all_state = list(product(*state))\n",
    "        # print(len(all_state))\n",
    "        return all_state[action_index]\n",
    "        \n",
    "    # hyper-parameter vector를 받아서 파라미터마다 가능한 값을 2차원으로 반환해주는 함수 ex)[[90, 100, 110], [2, 4, 6], [20, 25, 30], ...]\n",
    "    def make_state_ver2(self, cur_comb):\n",
    "        state = []\n",
    "        for name, cur, comb in zip(self.hyperparameter_list, cur_comb, self.comb_config):\n",
    "            state.append(self.check_bound_ver2([name,cur,comb]))\n",
    "        # print(state)\n",
    "        return state\n",
    "    \n",
    "    # env의 초기 state 설정, state는 hyper-parameter의 가능한 모든 조합으로 정의한다.\n",
    "    def reset(self):\n",
    "        init_hp = [random.randint(1, 100), random.randint(1, 100), random.randint(2, 100), random.randint(1, 100), random.random()/2, random.random()]\n",
    "        state = self.make_state(init_hp)\n",
    "        return state\n",
    "        \n",
    "    # action을 넣어서 next_state와 reward를 반환하는 함수\n",
    "    def step(self, state, action_index):\n",
    "        done = 0\n",
    "        cur_comb = state[action_index]\n",
    "        cur_hyperparameter = dict(zip(self.hyperparameter_list, cur_comb))\n",
    "        rf_model = h2y2_RF_Model(cur_hyperparameter)\n",
    "        reward = rf_model.evaluate()\n",
    "        next_state = self.make_state(cur_comb)\n",
    "        if reward == 1-self.epsilon:\n",
    "            done = 1\n",
    "        return next_state, reward, done\n",
    "\n",
    "    # action을 넣어서 next_state와 reward를 반환하는 함수 ver2\n",
    "    def step_ver2(self, state, action_index):\n",
    "        done = 0\n",
    "        cur_comb = self.mapping_action(state, action_index) # state에 맞게 현재 조합 매핑\n",
    "        cur_hyperparameter = dict(zip(self.hyperparameter_list, cur_comb))\n",
    "        rf_model = h2y2_RF_Model(cur_hyperparameter)\n",
    "        reward = rf_model.evaluate()\n",
    "        next_state = self.make_state_ver2(cur_comb)\n",
    "        if reward == 1-self.epsilon:\n",
    "            done = 1\n",
    "        return next_state, reward, done\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H2Y2_Agent:\n",
    "    def __init__(self):\n",
    "        self.gamma = 0.99 # discount factor\n",
    "        self.t_step = 0\n",
    "        self.learn_freq = 4\n",
    "        self.target_update_freq = 2000\n",
    "        self.batch_size = 32\n",
    "        self.action_size = 6\n",
    "\n",
    "        self.main_network = Network(input_size=(729,6), out_size=729).float().to(device)\n",
    "        self.target_network = Network(input_size=(729,6), out_size=729).float().to(device)\n",
    "        self.target_network.load_state_dict(self.main_network.state_dict())\n",
    "        \n",
    "        self.hidden_state, self.cell_state = self.main_network.init_hidden_states(bsize=1)\n",
    "        self.memory = ReplayBuffer(action_size = self.action_size, buffer_size = 10000, batch_size = self.batch_size, seed=42)\n",
    "        self.optimizer = optim.Adam(self.main_network.parameters(), lr = 0.01)\n",
    "\n",
    "    \n",
    "    def select_action(self, state, eps=0.):\n",
    "        # \"내부의 신경망에 state를 넣어 모든 q_value를 뽑고, argmax로 선택\"\n",
    "        \n",
    "        state = torch.from_numpy(np.array(state)).float().unsqueeze(0).to(device)\n",
    "        self.main_network.eval()\n",
    "        with torch.no_grad(): # 연산속도 증가\n",
    "            action_values, _ = self.main_network.forward(state, bsize=1, time_step=1, hidden_state=self.hidden_state, cell_state=self.cell_state)\n",
    "            # print(type(action_values)) # tuple\n",
    "        self.main_network.train()\n",
    "    \n",
    "        # q_value를 최대로 만드는 action의 인덱스를 선택한다.\n",
    "        if random.random() > eps:\n",
    "            max_index = torch.argmax(action_values)\n",
    "            return max_index\n",
    "        else:\n",
    "            random_index = random.choice(np.arange(self.action_size))\n",
    "            return random_index\n",
    "            \n",
    "    def step(self, state, action_index, reward, next_state, done):\n",
    "        # 메모리에 현재의 state, action_index, reward, next_state, done을 추가한다.\n",
    "        self.t_step += 1 \n",
    "        # print(self.t_step) # t_step은 episode가 바뀌어도 유지된다.\n",
    "        self.memory.add(state, action_index, reward, next_state, done)\n",
    "        \n",
    "        # target_update로 정해둔 step마다, target network의 파라미터를 업데이트 한다.\n",
    "        if (self.t_step % self.target_update_freq) == 0:\n",
    "            self.target_network.load_state_dict(self.main_network.state_dict())\n",
    "            \n",
    "        # learn_freq로 정해둔 step마다, batch_size만큼의 샘플을 가지고 main_network를 학습시킨다.\n",
    "        if (self.t_step % self.learn_freq) == 0:\n",
    "            # batch_size만큼의 sample이 memory에 있으면 학습을 실행한다.\n",
    "            if len(self.memory) > self.batch_size:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, self.gamma)\n",
    "    \n",
    "    # main_network의 파라미터를 학습하는 함수\n",
    "    def learn(self, experiences, gamma):\n",
    "        states, actions, reward, next_states, dones = experiences\n",
    "        hidden_batch, cell_batch = self.main_network.init_hidden_states(bsize=self.batch_size)\n",
    "\n",
    "        # target_network를 통해 next_state에 대한 q_value 값을 도출하고, 그 중 max인 값을 선택한다.\n",
    "        Q_targets_next, _ = self.target_network.forward(next_states,bsize=self.batch_size, time_step=1, hidden_state=hidden_batch, cell_state=cell_batch)\n",
    "        Q_targets_next_max, __ = Q_targets_next.detach().max(dim=1)\n",
    "        Q_targets_next_max = Q_targets_next_max.view(-1,1)\n",
    "        # print(Q_targets_next_max.shape) # torch.Size([23328, 1]) -> torch.Size([32, 1])이 나와야함. -> 완료\n",
    "        \n",
    "        # q_value_target을 계산한다.\n",
    "        Q_targets = reward + (gamma * Q_targets_next_max)\n",
    "        # print(Q_targets.shape) # (32,1)\n",
    "\n",
    "        # main_network를 통해 현재 state와 action 대한 q_value를 도출한다.\n",
    "        Q_expected, _ = self.main_network.forward(states, bsize=self.batch_size, time_step=1, hidden_state=hidden_batch, cell_state=cell_batch)\n",
    "        # print(Q_expected.shape) # (32,729)\n",
    "        Q_expected_action = Q_expected.gather(dim=1, index = actions)\n",
    "        # print(Q_expected_action.shape) # (32,1)\n",
    "\n",
    "        loss = F.mse_loss(Q_expected_action, Q_targets)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "\n",
    "        self.action_size = action_size #각각의 action의 차원\n",
    "        self.memory = deque(maxlen=buffer_size)  #버퍼의 최대 크기\n",
    "        self.batch_size = batch_size # 배치 사이즈\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed) # 랜덤 시드\n",
    "    \n",
    "    # states, actions, rewards, next_states, done을 replay memory에 저장하는 함수\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    # replay memory에서 이전 과정에서 저장된 states, actions, rewards, next_states, done을 랜덤 추출하는 함수\n",
    "    def sample(self):\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([torch.as_tensor(e.state).cpu() for e in experiences if e is not None])).float().to(device)\n",
    "        # print(states.shape) # (32*729,6)\n",
    "        actions = torch.from_numpy(np.vstack([torch.as_tensor(e.action).cpu() for e in experiences if e is not None])).long().to(device)\n",
    "        # print(actions.shape) # (32,1)\n",
    "        rewards = torch.from_numpy(np.vstack([torch.as_tensor(e.reward).cpu() for e in experiences if e is not None])).float().to(device)\n",
    "        # print(rewards.shape) # (32,1)\n",
    "        next_states = torch.from_numpy(np.vstack([torch.as_tensor(e.next_state).cpu() for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([torch.as_tensor(e.done).cpu() for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "        # print(dones.shape) # (32,1)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gru도 비교해보면 좋다.\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size,out_size):\n",
    "        super(Network,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.out_size = out_size\n",
    "        \n",
    "        self.conv_layer1 = nn.Conv1d(in_channels=1,out_channels=32,kernel_size=8,stride=4)\n",
    "        self.conv_layer2 = nn.Conv1d(in_channels=32,out_channels=64,kernel_size=4,stride=2)\n",
    "        self.conv_layer3 = nn.Conv1d(in_channels=64,out_channels=64,kernel_size=3,stride=1)\n",
    "        self.conv_layer4 = nn.Conv1d(in_channels=64,out_channels=512,kernel_size=7,stride=1)\n",
    "        self.lstm_layer = nn.LSTM(input_size=512,hidden_size=512,num_layers=1,batch_first=True)\n",
    "        self.adv = nn.Linear(in_features=512,out_features=self.out_size)\n",
    "        self.val = nn.Linear(in_features=512,out_features=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x,bsize,time_step,hidden_state,cell_state):\n",
    "        x = x.view(bsize*time_step,1,-1)\n",
    "        \n",
    "        conv_out = self.conv_layer1(x)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        conv_out = self.conv_layer2(conv_out)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        conv_out = self.conv_layer3(conv_out)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        conv_out = self.conv_layer4(conv_out)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        # print(conv_out.shape) # [1,512,~]\n",
    "        \n",
    "        conv_out = conv_out.view(bsize, -1, 512)\n",
    "        \n",
    "        lstm_out = self.lstm_layer(conv_out,(hidden_state,cell_state))\n",
    "        out = lstm_out[0][:,time_step-1,:]\n",
    "        h_n = lstm_out[1][0]\n",
    "        c_n = lstm_out[1][1]\n",
    "        \n",
    "        adv_out = self.adv(out)\n",
    "        val_out = self.val(out)\n",
    "        \n",
    "        qout = val_out.expand(bsize,self.out_size) + (adv_out - adv_out.mean(dim=1).unsqueeze(dim=1).expand(bsize,self.out_size))\n",
    "        \n",
    "        return qout, (h_n,c_n)\n",
    "    \n",
    "    def init_hidden_states(self,bsize):\n",
    "        h = torch.zeros(1,bsize,512).float().to(device)\n",
    "        c = torch.zeros(1,bsize,512).float().to(device)\n",
    "        \n",
    "        return h,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple network\n",
    "q_network = nn.Sequential(\n",
    "    nn.Linear(6, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H2Y2:\n",
    "    def __init__(self):\n",
    "        self.agent = H2Y2_Agent()\n",
    "        self.env = H2Y2_env()\n",
    "        self.eps = 1.0 # 처음 epsilon\n",
    "        self.scores = []\n",
    "        self.end_times = []\n",
    "        \n",
    "    def dqn(self, n_episodes=10, max_t=10, eps_end=0.01, eps_decay=0.99):\n",
    "            \n",
    "        for i_episode in tqdm(range(1, n_episodes+1)):\n",
    "            print(f\"{i_episode} episode\")\n",
    "            state = self.env.reset()\n",
    "            score = 0\n",
    "            for t in range(1,max_t+1):\n",
    "                # print(f\"{t} time\")\n",
    "                action_index = self.agent.select_action(state, self.eps)\n",
    "                next_state, reward, done = self.env.step(state, action_index)\n",
    "                self.agent.step(state, action_index, reward, next_state, done)\n",
    "                state = next_state\n",
    "                score += reward\n",
    "                if done:\n",
    "                    break\n",
    "            self.scores.append(score) # 하나의 episode에 대한 score(reward)를 저장\n",
    "            self.end_times.append(t) # 몇번의 step을 통해 done에 도달하는지 확인\n",
    "            self.eps = max(eps_end, eps_decay*self.eps) # decrease epsilon\n",
    "\n",
    "            if i_episode % 5 == 0:\n",
    "                torch.save(self.agent.main_network.state_dict(),f'./model/{i_episode}_cpu_test.pt') \n",
    "        # model save\n",
    "        torch.save(self.agent.main_network.state_dict(),'./model/cpu_test.pt')\n",
    "        return np.mean(self.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 episode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:12,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 episode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:03<00:12,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 episode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:03<00:08,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 episode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:09<00:18,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 episode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:15<00:20,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 episode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:25<00:24,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 episode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:31<00:18,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 episode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:39<00:13,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 episode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:45<00:06,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 episode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:53<00:00,  5.31s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.340935672514621"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "\n",
    "h2y2 = H2Y2()\n",
    "\n",
    "h2y2.dqn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.736842105263158,\n",
       " 9.210526315789476,\n",
       " 6.3157894736842115,\n",
       " 6.3157894736842115,\n",
       " 7.140350877192983,\n",
       " 6.3157894736842115,\n",
       " 6.3157894736842115,\n",
       " 6.3157894736842115,\n",
       " 7.257309941520469,\n",
       " 9.485380116959066]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2y2.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729\n",
      "0.9415204678362573\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "def main():\n",
    "    env = H2Y2_env()\n",
    "    agent = H2Y2_Agent()\n",
    "    state = env.reset()\n",
    "    print(len(state))\n",
    "    next_state, reward, done = env.step(state, 48)\n",
    "    print(reward)\n",
    "    print(done)\n",
    "    \n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()\n",
    "    \n",
    "# 실험해보면 좋을 것\n",
    "# 1. 다음달에 새로운 데이터가 추가되었을 때도 잘 동작하는가 ( 데이터가 점진적으로 추가되었을 때 사용이 가능한가 )\n",
    "# 2. 그리드서치, 랜덤서치, 베이지안 서치랑 비교\n",
    "# 3. 데이터 도메인이 완전히 변경되었을 때도 lstm 레이어만 파인튜닝 튜닝하는 것으로 성능이 좋을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 파라미터를 불러와서 하이퍼파라미터 튜닝\n",
    "\n",
    "h2y2_test = H2Y2()\n",
    "weights = torch.load('model/CNN_LSTM_WEIGHTS_50epoch_10000max_t.pt', map_location='cpu')\n",
    "h2y2_test.agent.main_network.load_state_dict(weights)\n",
    "max_t = 100\n",
    "scores = []\n",
    "done_t = []\n",
    "\n",
    "for episode in range(1):\n",
    "    state = h2y2_test.env.reset()\n",
    "    for t in range(1,max_t+1):\n",
    "        action_index = h2y2_test.agent.select_action(state, 0.01)\n",
    "        next_state, reward, done = h2y2_test.env.step(state, action_index)\n",
    "        state = next_state\n",
    "        scores.append(reward)\n",
    "        done_t.append(done)\n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "\n",
    "# 1000번 step에 2분 소요\n",
    "# 500번 step에 1분 소요\n",
    "# 100번 step에 15초 소요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9532163742690059\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(scores)\n",
    "print(max(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(done_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid Search :  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = {'n_estimators': [10, 50, 100],\n",
    "               'max_depth': [2, 4, 6],\n",
    "               'min_samples_leaf': [1, 2, 3],\n",
    "               'min_samples_split': [2, 3, 4],\n",
    "               'min_weight_fraction_leaf': [0.1, 0.2, 0.3],\n",
    "               'min_impurity_decrease': [0.1, 0.2, 0.3],\n",
    "               }\n",
    "data = load_breast_cancer()\n",
    "x_data = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y_data = data.target\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_data, y_data, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "model = GridSearchCV(estimator = clf, param_grid = grid_search)\n",
    "model.fit(train_x,train_y)\n",
    "predict = model.best_estimator_.predict(test_x)\n",
    "print(\"\\nGrid Search : \", accuracy_score(test_y, predict))\n",
    "\n",
    "# 하이퍼파라미터 6개를 각각 5개씩 지정하여 돌렸을 때 (5^6 = 15625),\n",
    "# 시간은 정말 많이...(1번당 5초가 걸린다고 했을 때, 15625*5초 = 21시간) 소요된다.\n",
    "\n",
    "# 하이퍼파라미터 6개를 각각 3개씩 지정하여 돌렸을 때, (3^6 = 729)\n",
    "# 시간은 5분이 걸린다.\n",
    "# 정확도는 Grid Search :  0.9473684210526315\n",
    "\n",
    "# 단점: 모든 조합을 다 해볼 순 있지만 시간이 매~우 많이 걸리고,\n",
    "#       다 해봤다고 하더라도 내가 지정해준 조합 내에서만 움직이는 것이므로 최적을 보장할 순 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Search :  0.9415204678362573\n"
     ]
    }
   ],
   "source": [
    "# random search (주어진 범위 내에서 임의의 조합을 선택하여 최적의 조합을 탐색)\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = {'n_estimators': [10, 50, 100, 150, 200],\n",
    "               'max_depth': [2, 4, 6, 8, 10],\n",
    "               'min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "               'min_samples_split': [2, 3, 4, 5, 6],\n",
    "               'min_weight_fraction_leaf': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "               'min_impurity_decrease': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "               }\n",
    "\n",
    "data = load_breast_cancer()\n",
    "x_data = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y_data = data.target\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_data, y_data, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "model = RandomizedSearchCV(estimator = clf, param_distributions = random_search, n_iter = 100, random_state= 42)\n",
    "model.fit(train_x,train_y)\n",
    "predict = model.best_estimator_.predict(test_x)\n",
    "print(\"\\nRandom Search : \", accuracy_score(test_y, predict))\n",
    "\n",
    "# 하이퍼파라미터 6개를 각각 5개씩 지정하여 iteration을 100번 돌렸을 때,\n",
    "# 시간은 1분 20초가 소요된다.\n",
    "# 정확도는 Random Search :  0.9415204678362573\n",
    "\n",
    "# 단점: 모든 조합을 다 안해봤을 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_im... | min_sa... | min_sa... | min_we... | n_esti... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.9532   \u001b[0m | \u001b[95m2.116    \u001b[0m | \u001b[95m0.1866   \u001b[0m | \u001b[95m1.601    \u001b[0m | \u001b[95m2.708    \u001b[0m | \u001b[95m0.1021   \u001b[0m | \u001b[95m48.8     \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.9591   \u001b[0m | \u001b[95m3.665    \u001b[0m | \u001b[95m0.1212   \u001b[0m | \u001b[95m1.182    \u001b[0m | \u001b[95m2.183    \u001b[0m | \u001b[95m0.1304   \u001b[0m | \u001b[95m30.99    \u001b[0m |\n",
      "| \u001b[95m40       \u001b[0m | \u001b[95m0.9649   \u001b[0m | \u001b[95m2.364    \u001b[0m | \u001b[95m0.1035   \u001b[0m | \u001b[95m1.608    \u001b[0m | \u001b[95m2.436    \u001b[0m | \u001b[95m0.1006   \u001b[0m | \u001b[95m21.03    \u001b[0m |\n",
      "=================================================================================================\n",
      "{'target': 0.9649122807017544, 'params': {'max_depth': 2.363543075462187, 'min_impurity_decrease': 0.10354888930058007, 'min_samples_leaf': 1.6075328905413064, 'min_samples_split': 2.4359611014830316, 'min_weight_fraction_leaf': 0.1005691372418353, 'n_estimators': 21.033617755126812}}\n",
      "\n",
      "Bayesian Search :  0.9415204678362573\n"
     ]
    }
   ],
   "source": [
    "# Bayesian optimization\n",
    "\n",
    "# 목적 함수\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def bayes_rf(n_estimators, max_depth, min_samples_leaf, min_samples_split, min_weight_fraction_leaf, min_impurity_decrease):\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=int(n_estimators),\n",
    "        max_depth = int(max_depth),\n",
    "        min_samples_leaf = int(min_samples_leaf),\n",
    "        min_samples_split = int(min_samples_split),\n",
    "        min_weight_fraction_leaf = min_weight_fraction_leaf,\n",
    "        min_impurity_decrease = min_impurity_decrease,\n",
    "        random_state=42)\n",
    "    \n",
    "    data = load_breast_cancer()\n",
    "    x_data = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "    y_data = data.target\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x_data, y_data, test_size=0.3, random_state=42)\n",
    "    \n",
    "    model.fit(train_x,train_y)\n",
    "    y_pred= model.predict(test_x)\n",
    "    \n",
    "    score=accuracy_score(y_pred, test_y)\n",
    "    \n",
    "    return score\n",
    "    \n",
    "\n",
    "# 베이지안 최적화\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "Bayesian_search = {'n_estimators': [10, 50],\n",
    "               'max_depth': [2, 4],\n",
    "               'min_samples_leaf': [1, 2],\n",
    "               'min_samples_split': [2, 3],\n",
    "               'min_weight_fraction_leaf': [0.1, 0.2],\n",
    "               'min_impurity_decrease': [0.1, 0.2]\n",
    "               }\n",
    "               \n",
    "bo = BayesianOptimization(f=bayes_rf, pbounds=Bayesian_search, verbose=1, random_state=42)\n",
    "bo.maximize(init_points=5, n_iter=100)\n",
    "\n",
    "print(bo.max)\n",
    "max_parameter = bo.max['params']\n",
    "max_parameter['n_estimators']=int(max_parameter['n_estimators'])\n",
    "max_parameter['max_depth']=int(max_parameter['max_depth'])\n",
    "max_parameter['min_samples_leaf']=int(max_parameter['min_samples_leaf'])\n",
    "max_parameter['min_samples_split']=int(max_parameter['min_samples_split'])\n",
    "\n",
    "\n",
    "bo_tuned_rf = RandomForestClassifier(**max_parameter)\n",
    "data = load_breast_cancer()\n",
    "x_data = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y_data = data.target\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_data, y_data, test_size=0.3, random_state=42)\n",
    "\n",
    "bo_tuned_rf.fit(train_x,train_y)\n",
    "y_pred= bo_tuned_rf.predict(test_x)\n",
    "print(\"\\nBayesian Search : \", accuracy_score(test_y, y_pred))\n",
    "\n",
    "# 하이퍼파라미터 6개를 각각 2개씩 지정하여 iteration을 100번 돌렸을 때, (각각 2개씩 지정하는 것이 라이브러리 최대값임.)\n",
    "# 시간은 15초가 소요된다.\n",
    "# 정확도는 Bayesian Search :  0.9415204678362573\n",
    "\n",
    "# 단점 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결론\n",
    "# DQL을 사용한 하이퍼파라미터 튜닝의 성능이 가장 좋게 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.16 ('h2y2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53e991c9edeba9e61f5fc5dc21b635cf9d5ecc55b271a0f82c627d18cdfb2087"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
