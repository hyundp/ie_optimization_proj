{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    \\n    더 나아가서,\\n    1. multi agent를 사용해야하나?\\n    \\n    state 설정\\n    만약 넣은 state가 100,None,2,1,0,0(defalut) 라면, action value는 \\n    3^6=729개의 조합에 대해 q-value를 뽑고 그 중 하나를 고르는 것.\\n    따라서 state는 (729, 6)의 크기를 갖는다.\\n    \\n    deep q 이유\\n    만약 일반 q learning을 쓸 때, \\n    하나의 하이퍼파라미터 당 10개의 tracking을 한다고 가정하면, 10^6만큼의 q-table이 필요하게 된다.\\n    따라서 시/공간 효율성을 위해 하이퍼파라미터 조합에 대한 q-value 값을 표현해주는 신경망을 학습시키는 것이 도움이 될 수 있다.\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    정리\n",
    "    1. agent를 통해서 policy(랜덤값이 앱실론보다 작으면 랜덤 인덱스와 랜덤 action을, \n",
    "                            그렇지 않으면 내부 신경망(LSTM)에 state값을 넣어 \n",
    "                            가능한 모든 action에 대한 action_values(Q_values) 중 가장 큰 값에 해당하는 인덱스와 그 값을 반환한다.\n",
    "                            이때 사용되는 내부 신경망은 main_network이다.)\n",
    "        에 맞는 action_index와 action_value를 찾아낸다.\n",
    "    2. 찾아낸 action_index와 action_value를 env에 넣어서 RF 모델을 돌린 뒤 next_state(다음 action 집합)와 reward(정확도)를 찾아낸다.\n",
    "    3. memory(replay buffer)에 현재 state와 action_index, 그리고 위에서 도출된 next_state, reward를 넣는다.\n",
    "    4. replay buffer에서 원하는 batch size만큼 sample(state, action_index, reward, next_state)을 뽑아낸다.\n",
    "    5. sample의 state를 main_network에 넣어서 도출된 값들 중 action index에 맞는 값을 뽑고 이를 main Q 값으로 한다.\n",
    "    6. sample의 next_state를 target_network에 넣어서 값을 도출한 뒤, 그 중 가장 큰 값을 찾아낸다.\n",
    "    7. 위에서 찾아낸 값을 Q라고 한다면, reward + gamma(discount factor)*Q = target Q로 정한다.\n",
    "    8. mainQ와 targetQ를 loss function에 넣어서 내부 신경망 파라미터를 역전파로 업데이트 한다. 이때 옵티마이저도 사용된다.\n",
    "    9. 이 과정을 반복하여 main Q가 target Q에 가까워질 수 있게 한다.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"    \n",
    "    더 나아가서,\n",
    "    1. multi agent를 사용해야하나?\n",
    "    \n",
    "    state 설정\n",
    "    만약 넣은 state가 100,None,2,1,0,0(defalut) 라면, action value는 \n",
    "    3^6=729개의 조합에 대해 q-value를 뽑고 그 중 하나를 고르는 것.\n",
    "    따라서 state는 (729, 6)의 크기를 갖는다.\n",
    "    \n",
    "    deep q 이유\n",
    "    만약 일반 q learning을 쓸 때, \n",
    "    하나의 하이퍼파라미터 당 10개의 tracking을 한다고 가정하면, 10^6만큼의 q-table이 필요하게 된다.\n",
    "    따라서 시/공간 효율성을 위해 하이퍼파라미터 조합에 대한 q-value 값을 표현해주는 신경망을 학습시키는 것이 도움이 될 수 있다.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import deque, namedtuple\n",
    "import copy\n",
    "from itertools import product\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "class h2y2_RF_Model():\n",
    "    def __init__(self, cur_hyperparameter):\n",
    "        self.model = RandomForestClassifier(**cur_hyperparameter, random_state=42)\n",
    "        self.data = load_breast_cancer()\n",
    "        x_data = pd.DataFrame(self.data.data, columns=self.data.feature_names)\n",
    "        y_data = self.data.target\n",
    "        self.train_x, self.test_x, self.train_y, self.test_y = train_test_split(x_data, y_data, test_size=0.3, random_state=42)\n",
    "        \n",
    "        \n",
    "    def evaluate(self):\n",
    "        self.model.fit(self.train_x, self.train_y)\n",
    "        predict = self.model.predict(self.test_x)\n",
    "        return accuracy_score(self.test_y, predict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H2Y2_env:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # initial\n",
    "        self.comb_config = [[-50,0,50], [-2,0,2], [-1,0,1], [-1,0,1], [-0.1,0,0.1], [-0.1,0,0.1]]\n",
    "        self.hyperparameter_list = ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'min_weight_fraction_leaf', 'min_impurity_decrease']\n",
    "        self.epsilon = 1e-5\n",
    "    \n",
    "    # 하이퍼파라미터의 범위를 제한해주는 함수 ver1\n",
    "    def check_bound(self, comb):        \n",
    "        comb_sum = comb[1] + comb[2]\n",
    "        if comb[0] == 'n_estimators':\n",
    "            if comb_sum > 0:\n",
    "                return int(comb_sum)\n",
    "        elif comb[0] == 'max_depth':\n",
    "            if comb_sum > 0:\n",
    "                return int(comb_sum)\n",
    "        elif comb[0] == 'min_samples_leaf':\n",
    "            if comb_sum > 0:\n",
    "                return int(comb_sum)\n",
    "        elif comb[0] == 'min_samples_split':\n",
    "            if comb_sum > 1:\n",
    "                return int(comb_sum)\n",
    "        elif comb[0] == 'min_weight_fraction_leaf':\n",
    "            if comb_sum >= 0 and comb_sum <= 0.5:\n",
    "                return float(comb_sum)\n",
    "        elif comb[0] == 'min_impurity_decrease':\n",
    "            if comb_sum >= 0 and comb_sum <= 1:\n",
    "                return float(comb_sum)\n",
    "        return comb[1]\n",
    "    \n",
    "    # 하이퍼파라미터의 범위를 제한해주는 함수 ver2\n",
    "    def check_bound_ver2(self, comb):\n",
    "        sample_state = []\n",
    "        for i in range(len(comb[2])):\n",
    "            comb_sum = comb[1] + comb[2][i]\n",
    "            if comb[0] == 'n_estimators':\n",
    "                if comb_sum > 0:\n",
    "                    sample_state.append(int(comb_sum))\n",
    "            elif comb[0] == 'max_depth':\n",
    "                if comb_sum > 0:\n",
    "                    sample_state.append(int(comb_sum))\n",
    "            elif comb[0] == 'min_samples_leaf':\n",
    "                if comb_sum > 0:\n",
    "                    sample_state.append(int(comb_sum))\n",
    "            elif comb[0] == 'min_samples_split':\n",
    "                if comb_sum > 1:\n",
    "                    sample_state.append(int(comb_sum))\n",
    "            elif comb[0] == 'min_weight_fraction_leaf':\n",
    "                if comb_sum >= 0 and comb_sum <= 0.5:\n",
    "                    sample_state.append(float(comb_sum))\n",
    "            elif comb[0] == 'min_impurity_decrease':\n",
    "                if comb_sum >= 0 and comb_sum <= 1:\n",
    "                    sample_state.append(float(comb_sum))\n",
    "            else:\n",
    "                sample_state.append(comb[1])\n",
    "        return sample_state\n",
    "    \n",
    "    # hyper-parameter vector를 받아서 다음으로 가능한 모든 조합을 반환해주는 함수\n",
    "    def make_state(self, cur_comb):\n",
    "        comb = list(product(*self.comb_config))\n",
    "        state = [tuple(map(self.check_bound, zip(self.hyperparameter_list, cur_comb, tuple_comb))) for tuple_comb in comb]\n",
    "        # print(state)\n",
    "        return state\n",
    "        \n",
    "    # q_value로 도출된 action_index가 어떤 observation을 가리키는지 확인한다.\n",
    "    def mapping_action(self, state, action_index):\n",
    "        all_state = list(product(*state))\n",
    "        # print(len(all_state))\n",
    "        return all_state[action_index]\n",
    "        \n",
    "    # hyper-parameter vector를 받아서 파라미터마다 가능한 값을 2차원으로 반환해주는 함수 ex)[[90, 100, 110], [2, 4, 6], [20, 25, 30], ...]\n",
    "    def make_state_ver2(self, cur_comb):\n",
    "        state = []\n",
    "        for name, cur, comb in zip(self.hyperparameter_list, cur_comb, self.comb_config):\n",
    "            state.append(self.check_bound_ver2([name,cur,comb]))\n",
    "        # print(state)\n",
    "        return state\n",
    "    \n",
    "    # env의 초기 state 설정, state는 hyper-parameter의 가능한 모든 조합으로 정의한다.\n",
    "    def reset(self):\n",
    "        init_hp = [random.randint(1, 100), random.randint(1, 100), random.randint(2, 100), random.randint(1, 100), random.random()/2, random.random()]\n",
    "        state = self.make_state(init_hp)\n",
    "        return state\n",
    "        \n",
    "    # action을 넣어서 next_state와 reward를 반환하는 함수\n",
    "    def step(self, state, action_index):\n",
    "        done = 0\n",
    "        cur_comb = state[action_index]\n",
    "        cur_hyperparameter = dict(zip(self.hyperparameter_list, cur_comb))\n",
    "        rf_model = h2y2_RF_Model(cur_hyperparameter)\n",
    "        reward = rf_model.evaluate()\n",
    "        next_state = self.make_state(cur_comb)\n",
    "        if reward == 1-self.epsilon:\n",
    "            done = 1\n",
    "        return next_state, reward, done\n",
    "\n",
    "    # action을 넣어서 next_state와 reward를 반환하는 함수 ver2\n",
    "    def step_ver2(self, state, action_index):\n",
    "        done = 0\n",
    "        cur_comb = self.mapping_action(state, action_index) # state에 맞게 현재 조합 매핑\n",
    "        cur_hyperparameter = dict(zip(self.hyperparameter_list, cur_comb))\n",
    "        rf_model = h2y2_RF_Model(cur_hyperparameter)\n",
    "        reward = rf_model.evaluate()\n",
    "        next_state = self.make_state_ver2(cur_comb)\n",
    "        if reward == 1:\n",
    "            done = 1\n",
    "        return next_state, reward, done\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H2Y2_Agent:\n",
    "    def __init__(self):\n",
    "        self.gamma = 0.99 # discount factor\n",
    "        self.t_step = 0\n",
    "        self.learn_freq = 4\n",
    "        self.target_update_freq = 2000\n",
    "        self.batch_size = 32\n",
    "        self.action_size = 6\n",
    "\n",
    "        self.main_network = Network(input_size=(729,6), out_size=729).float().to(device)\n",
    "        self.target_network = Network(input_size=(729,6), out_size=729).float().to(device)\n",
    "        self.target_network.load_state_dict(self.main_network.state_dict())\n",
    "        \n",
    "        self.hidden_state, self.cell_state = self.main_network.init_hidden_states(bsize=1)\n",
    "        self.memory = ReplayBuffer(action_size = self.action_size, buffer_size = 10000, batch_size = self.batch_size, seed=42)\n",
    "        self.optimizer = optim.Adam(self.main_network.parameters(), lr = 0.01)\n",
    "\n",
    "    \n",
    "    def select_action(self, state, eps=0.):\n",
    "        # \"내부의 신경망에 state를 넣어 모든 q_value를 뽑고, argmax로 선택\"\n",
    "        \n",
    "        state = torch.from_numpy(np.array(state)).float().unsqueeze(0).to(device)\n",
    "        self.main_network.eval()\n",
    "        with torch.no_grad(): # 연산속도 증가\n",
    "            action_values, _ = self.main_network.forward(state, bsize=1, time_step=1, hidden_state=self.hidden_state, cell_state=self.cell_state)\n",
    "            # print(type(action_values)) # tuple\n",
    "        self.main_network.train()\n",
    "    \n",
    "        # q_value를 최대로 만드는 action의 인덱스를 선택한다.\n",
    "        if random.random() > eps:\n",
    "            max_index = torch.argmax(action_values)\n",
    "            return max_index\n",
    "        else:\n",
    "            random_index = random.choice(np.arange(self.action_size))\n",
    "            return random_index\n",
    "            \n",
    "    def step(self, state, action_index, reward, next_state, done):\n",
    "        # 메모리에 현재의 state, action_index, reward, next_state, done을 추가한다.\n",
    "        self.t_step += 1 \n",
    "        # print(self.t_step) # t_step은 episode가 바뀌어도 유지된다.\n",
    "        self.memory.add(state, action_index, reward, next_state, done)\n",
    "        \n",
    "        # target_update로 정해둔 step마다, target network의 파라미터를 업데이트 한다.\n",
    "        if (self.t_step % self.target_update_freq) == 0:\n",
    "            self.target_network.load_state_dict(self.main_network.state_dict())\n",
    "            \n",
    "        # learn_freq로 정해둔 step마다, batch_size만큼의 샘플을 가지고 main_network를 학습시킨다.\n",
    "        if (self.t_step % self.learn_freq) == 0:\n",
    "            # batch_size만큼의 sample이 memory에 있으면 학습을 실행한다.\n",
    "            if len(self.memory) > self.batch_size:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, self.gamma)\n",
    "    \n",
    "    # main_network의 파라미터를 학습하는 함수\n",
    "    def learn(self, experiences, gamma):\n",
    "        states, actions, reward, next_states, dones = experiences\n",
    "        hidden_batch, cell_batch = self.main_network.init_hidden_states(bsize=self.batch_size)\n",
    "\n",
    "        # target_network를 통해 next_state에 대한 q_value 값을 도출하고, 그 중 max인 값을 선택한다.\n",
    "        Q_targets_next, _ = self.target_network.forward(next_states,bsize=self.batch_size, time_step=1, hidden_state=hidden_batch, cell_state=cell_batch)\n",
    "        Q_targets_next_max, __ = Q_targets_next.detach().max(dim=1)\n",
    "        Q_targets_next_max = Q_targets_next_max.view(-1,1)\n",
    "        # print(Q_targets_next_max.shape) # torch.Size([23328, 1]) -> torch.Size([32, 1])이 나와야함. -> 완료\n",
    "        \n",
    "        # q_value_target을 계산한다.\n",
    "        Q_targets = reward + (gamma * Q_targets_next_max)\n",
    "        # print(Q_targets.shape) # (32,1)\n",
    "\n",
    "        # main_network를 통해 현재 state와 action 대한 q_value를 도출한다.\n",
    "        Q_expected, _ = self.main_network.forward(states, bsize=self.batch_size, time_step=1, hidden_state=hidden_batch, cell_state=cell_batch)\n",
    "        # print(Q_expected.shape) # (32,729)\n",
    "        Q_expected_action = Q_expected.gather(dim=1, index = actions)\n",
    "        # print(Q_expected_action.shape) # (32,1)\n",
    "\n",
    "        loss = F.mse_loss(Q_expected_action, Q_targets)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "\n",
    "        self.action_size = action_size #각각의 action의 차원\n",
    "        self.memory = deque(maxlen=buffer_size)  #버퍼의 최대 크기\n",
    "        self.batch_size = batch_size # 배치 사이즈\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed) # 랜덤 시드\n",
    "    \n",
    "    # states, actions, rewards, next_states, done을 replay memory에 저장하는 함수\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    # replay memory에서 이전 과정에서 저장된 states, actions, rewards, next_states, done을 랜덤 추출하는 함수\n",
    "    def sample(self):\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        # print(states.shape) # (32*729,6)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        # print(actions.shape) # (32,1)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        # print(rewards.shape) # (32,1)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "        # print(dones.shape) # (32,1)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gru도 비교해보면 좋다.\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size,out_size):\n",
    "        super(Network,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.out_size = out_size\n",
    "        \n",
    "        self.conv_layer1 = nn.Conv1d(in_channels=1,out_channels=32,kernel_size=8,stride=4)\n",
    "        self.conv_layer2 = nn.Conv1d(in_channels=32,out_channels=64,kernel_size=4,stride=2)\n",
    "        self.conv_layer3 = nn.Conv1d(in_channels=64,out_channels=64,kernel_size=3,stride=1)\n",
    "        self.conv_layer4 = nn.Conv1d(in_channels=64,out_channels=512,kernel_size=7,stride=1)\n",
    "        self.lstm_layer = nn.LSTM(input_size=512,hidden_size=512,num_layers=1,batch_first=True)\n",
    "        self.adv = nn.Linear(in_features=512,out_features=self.out_size)\n",
    "        self.val = nn.Linear(in_features=512,out_features=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x,bsize,time_step,hidden_state,cell_state):\n",
    "        x = x.view(bsize*time_step,1,-1)\n",
    "        \n",
    "        conv_out = self.conv_layer1(x)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        conv_out = self.conv_layer2(conv_out)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        conv_out = self.conv_layer3(conv_out)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        conv_out = self.conv_layer4(conv_out)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        # print(conv_out.shape) # [1,512,~]\n",
    "        \n",
    "        conv_out = conv_out.view(bsize, -1, 512)\n",
    "        \n",
    "        lstm_out = self.lstm_layer(conv_out,(hidden_state,cell_state))\n",
    "        out = lstm_out[0][:,time_step-1,:]\n",
    "        h_n = lstm_out[1][0]\n",
    "        c_n = lstm_out[1][1]\n",
    "        \n",
    "        adv_out = self.adv(out)\n",
    "        val_out = self.val(out)\n",
    "        \n",
    "        qout = val_out.expand(bsize,self.out_size) + (adv_out - adv_out.mean(dim=1).unsqueeze(dim=1).expand(bsize,self.out_size))\n",
    "        \n",
    "        return qout, (h_n,c_n)\n",
    "    \n",
    "    def init_hidden_states(self,bsize):\n",
    "        h = torch.zeros(1,bsize,512).float().to(device)\n",
    "        c = torch.zeros(1,bsize,512).float().to(device)\n",
    "        \n",
    "        return h,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple network\n",
    "q_network = nn.Sequential(\n",
    "    nn.Linear(6, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H2Y2:\n",
    "    def __init__(self):\n",
    "        self.agent = H2Y2_Agent()\n",
    "        self.env = H2Y2_env()\n",
    "        self.eps = 1.0 # 처음 epsilon\n",
    "        self.scores = []\n",
    "        \n",
    "    def dqn(self, n_episodes=100, max_t=2000, eps_end=0.01, eps_decay=0.99):\n",
    "            \n",
    "        for i_episode in tqdm(range(1, n_episodes+1)):\n",
    "            print(f\"{i_episode} episode\")\n",
    "            state = self.env.reset()\n",
    "            score = 0\n",
    "            for t in range(1,max_t+1):\n",
    "                print(f\"{t} time\")\n",
    "                action_index = self.agent.select_action(state, self.eps)\n",
    "                next_state, reward, done = self.env.step(state, action_index)\n",
    "                self.agent.step(state, action_index, reward, next_state, done)\n",
    "                state = next_state\n",
    "                score += reward\n",
    "                if done:\n",
    "                    break\n",
    "            self.scores.append(score) # 하나의 episode에 대한 score(reward)를 저장\n",
    "            self.eps = max(eps_end, eps_decay*self.eps) # decrease epsilon\n",
    "            # if np.mean(self.scores_window)>=200.0:\n",
    "            #     break\n",
    "            \n",
    "        # model save\n",
    "        torch.save(self.agent.main_network.state_dict(),'./model/CNN_LSTM_WEIGHTS.pt')\n",
    "        return np.mean(self.scores_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 episode\n",
      "1 time\n",
      "2 time\n",
      "3 time\n",
      "4 time\n",
      "5 time\n",
      "6 time\n",
      "7 time\n",
      "8 time\n",
      "9 time\n",
      "10 time\n",
      "11 time\n",
      "12 time\n",
      "13 time\n",
      "14 time\n",
      "15 time\n",
      "16 time\n",
      "17 time\n",
      "18 time\n",
      "19 time\n",
      "20 time\n",
      "21 time\n",
      "22 time\n",
      "23 time\n",
      "24 time\n",
      "25 time\n",
      "26 time\n",
      "27 time\n",
      "28 time\n",
      "29 time\n",
      "30 time\n",
      "31 time\n",
      "32 time\n",
      "33 time\n",
      "34 time\n",
      "35 time\n",
      "36 time\n",
      "37 time\n",
      "38 time\n",
      "39 time\n",
      "40 time\n",
      "41 time\n",
      "42 time\n",
      "43 time\n",
      "44 time\n",
      "45 time\n",
      "46 time\n",
      "47 time\n",
      "48 time\n",
      "49 time\n",
      "50 time\n",
      "51 time\n",
      "52 time\n",
      "53 time\n",
      "54 time\n",
      "55 time\n",
      "56 time\n",
      "57 time\n",
      "58 time\n",
      "59 time\n",
      "60 time\n",
      "61 time\n",
      "62 time\n",
      "63 time\n",
      "64 time\n",
      "65 time\n",
      "66 time\n",
      "67 time\n",
      "68 time\n",
      "69 time\n",
      "70 time\n",
      "71 time\n",
      "72 time\n",
      "73 time\n",
      "74 time\n",
      "75 time\n",
      "76 time\n",
      "77 time\n",
      "78 time\n",
      "79 time\n",
      "80 time\n",
      "81 time\n",
      "82 time\n",
      "83 time\n",
      "84 time\n",
      "85 time\n",
      "86 time\n",
      "87 time\n",
      "88 time\n",
      "89 time\n",
      "90 time\n",
      "91 time\n",
      "92 time\n",
      "93 time\n",
      "94 time\n",
      "95 time\n",
      "96 time\n",
      "97 time\n",
      "98 time\n",
      "99 time\n",
      "100 time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [02:04<18:38, 124.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 episode\n",
      "1 time\n",
      "2 time\n",
      "3 time\n",
      "4 time\n",
      "5 time\n",
      "6 time\n",
      "7 time\n",
      "8 time\n",
      "9 time\n",
      "10 time\n",
      "11 time\n",
      "12 time\n",
      "13 time\n",
      "14 time\n",
      "15 time\n",
      "16 time\n",
      "17 time\n",
      "18 time\n",
      "19 time\n",
      "20 time\n",
      "21 time\n",
      "22 time\n",
      "23 time\n",
      "24 time\n",
      "25 time\n",
      "26 time\n",
      "27 time\n",
      "28 time\n",
      "29 time\n",
      "30 time\n",
      "31 time\n",
      "32 time\n",
      "33 time\n",
      "34 time\n",
      "35 time\n",
      "36 time\n",
      "37 time\n",
      "38 time\n",
      "39 time\n",
      "40 time\n",
      "41 time\n",
      "42 time\n",
      "43 time\n",
      "44 time\n",
      "45 time\n",
      "46 time\n",
      "47 time\n",
      "48 time\n",
      "49 time\n",
      "50 time\n",
      "51 time\n",
      "52 time\n",
      "53 time\n",
      "54 time\n",
      "55 time\n",
      "56 time\n",
      "57 time\n",
      "58 time\n",
      "59 time\n",
      "60 time\n",
      "61 time\n",
      "62 time\n",
      "63 time\n",
      "64 time\n",
      "65 time\n",
      "66 time\n",
      "67 time\n",
      "68 time\n",
      "69 time\n",
      "70 time\n",
      "71 time\n",
      "72 time\n",
      "73 time\n",
      "74 time\n",
      "75 time\n",
      "76 time\n",
      "77 time\n",
      "78 time\n",
      "79 time\n",
      "80 time\n",
      "81 time\n",
      "82 time\n",
      "83 time\n",
      "84 time\n",
      "85 time\n",
      "86 time\n",
      "87 time\n",
      "88 time\n",
      "89 time\n",
      "90 time\n",
      "91 time\n",
      "92 time\n",
      "93 time\n",
      "94 time\n",
      "95 time\n",
      "96 time\n",
      "97 time\n",
      "98 time\n",
      "99 time\n",
      "100 time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [05:18<22:02, 165.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 episode\n",
      "1 time\n",
      "2 time\n",
      "3 time\n",
      "4 time\n",
      "5 time\n",
      "6 time\n",
      "7 time\n",
      "8 time\n",
      "9 time\n",
      "10 time\n",
      "11 time\n",
      "12 time\n",
      "13 time\n",
      "14 time\n",
      "15 time\n",
      "16 time\n",
      "17 time\n",
      "18 time\n",
      "19 time\n",
      "20 time\n",
      "21 time\n",
      "22 time\n",
      "23 time\n",
      "24 time\n",
      "25 time\n",
      "26 time\n",
      "27 time\n",
      "28 time\n",
      "29 time\n",
      "30 time\n",
      "31 time\n",
      "32 time\n",
      "33 time\n",
      "34 time\n",
      "35 time\n",
      "36 time\n",
      "37 time\n",
      "38 time\n",
      "39 time\n",
      "40 time\n",
      "41 time\n",
      "42 time\n",
      "43 time\n",
      "44 time\n",
      "45 time\n",
      "46 time\n",
      "47 time\n",
      "48 time\n",
      "49 time\n",
      "50 time\n",
      "51 time\n",
      "52 time\n",
      "53 time\n",
      "54 time\n",
      "55 time\n",
      "56 time\n",
      "57 time\n",
      "58 time\n",
      "59 time\n",
      "60 time\n",
      "61 time\n",
      "62 time\n",
      "63 time\n",
      "64 time\n",
      "65 time\n",
      "66 time\n",
      "67 time\n",
      "68 time\n",
      "69 time\n",
      "70 time\n",
      "71 time\n",
      "72 time\n",
      "73 time\n",
      "74 time\n",
      "75 time\n",
      "76 time\n",
      "77 time\n",
      "78 time\n",
      "79 time\n",
      "80 time\n",
      "81 time\n",
      "82 time\n",
      "83 time\n",
      "84 time\n",
      "85 time\n",
      "86 time\n",
      "87 time\n",
      "88 time\n",
      "89 time\n",
      "90 time\n",
      "91 time\n",
      "92 time\n",
      "93 time\n",
      "94 time\n",
      "95 time\n",
      "96 time\n",
      "97 time\n",
      "98 time\n",
      "99 time\n",
      "100 time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [08:32<20:50, 178.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 episode\n",
      "1 time\n",
      "2 time\n",
      "3 time\n",
      "4 time\n",
      "5 time\n",
      "6 time\n",
      "7 time\n",
      "8 time\n",
      "9 time\n",
      "10 time\n",
      "11 time\n",
      "12 time\n",
      "13 time\n",
      "14 time\n",
      "15 time\n",
      "16 time\n",
      "17 time\n",
      "18 time\n",
      "19 time\n",
      "20 time\n",
      "21 time\n",
      "22 time\n",
      "23 time\n",
      "24 time\n",
      "25 time\n",
      "26 time\n",
      "27 time\n",
      "28 time\n",
      "29 time\n",
      "30 time\n",
      "31 time\n",
      "32 time\n",
      "33 time\n",
      "34 time\n",
      "35 time\n",
      "36 time\n",
      "37 time\n",
      "38 time\n",
      "39 time\n",
      "40 time\n",
      "41 time\n",
      "42 time\n",
      "43 time\n",
      "44 time\n",
      "45 time\n",
      "46 time\n",
      "47 time\n",
      "48 time\n",
      "49 time\n",
      "50 time\n",
      "51 time\n",
      "52 time\n",
      "53 time\n",
      "54 time\n",
      "55 time\n",
      "56 time\n",
      "57 time\n",
      "58 time\n",
      "59 time\n",
      "60 time\n",
      "61 time\n",
      "62 time\n",
      "63 time\n",
      "64 time\n",
      "65 time\n",
      "66 time\n",
      "67 time\n",
      "68 time\n",
      "69 time\n",
      "70 time\n",
      "71 time\n",
      "72 time\n",
      "73 time\n",
      "74 time\n",
      "75 time\n",
      "76 time\n",
      "77 time\n",
      "78 time\n",
      "79 time\n",
      "80 time\n",
      "81 time\n",
      "82 time\n",
      "83 time\n",
      "84 time\n",
      "85 time\n",
      "86 time\n",
      "87 time\n",
      "88 time\n",
      "89 time\n",
      "90 time\n",
      "91 time\n",
      "92 time\n",
      "93 time\n",
      "94 time\n",
      "95 time\n",
      "96 time\n",
      "97 time\n",
      "98 time\n",
      "99 time\n",
      "100 time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [11:55<18:48, 188.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 episode\n",
      "1 time\n",
      "2 time\n",
      "3 time\n",
      "4 time\n",
      "5 time\n",
      "6 time\n",
      "7 time\n",
      "8 time\n",
      "9 time\n",
      "10 time\n",
      "11 time\n",
      "12 time\n",
      "13 time\n",
      "14 time\n",
      "15 time\n",
      "16 time\n",
      "17 time\n",
      "18 time\n",
      "19 time\n",
      "20 time\n",
      "21 time\n",
      "22 time\n",
      "23 time\n",
      "24 time\n",
      "25 time\n",
      "26 time\n",
      "27 time\n",
      "28 time\n",
      "29 time\n",
      "30 time\n",
      "31 time\n",
      "32 time\n",
      "33 time\n",
      "34 time\n",
      "35 time\n",
      "36 time\n",
      "37 time\n",
      "38 time\n",
      "39 time\n",
      "40 time\n",
      "41 time\n",
      "42 time\n",
      "43 time\n",
      "44 time\n",
      "45 time\n",
      "46 time\n",
      "47 time\n",
      "48 time\n",
      "49 time\n",
      "50 time\n",
      "51 time\n",
      "52 time\n",
      "53 time\n",
      "54 time\n",
      "55 time\n",
      "56 time\n",
      "57 time\n",
      "58 time\n",
      "59 time\n",
      "60 time\n",
      "61 time\n",
      "62 time\n",
      "63 time\n",
      "64 time\n",
      "65 time\n",
      "66 time\n",
      "67 time\n",
      "68 time\n",
      "69 time\n",
      "70 time\n",
      "71 time\n",
      "72 time\n",
      "73 time\n",
      "74 time\n",
      "75 time\n",
      "76 time\n",
      "77 time\n",
      "78 time\n",
      "79 time\n",
      "80 time\n",
      "81 time\n",
      "82 time\n",
      "83 time\n",
      "84 time\n",
      "85 time\n",
      "86 time\n",
      "87 time\n",
      "88 time\n",
      "89 time\n",
      "90 time\n",
      "91 time\n",
      "92 time\n",
      "93 time\n",
      "94 time\n",
      "95 time\n",
      "96 time\n",
      "97 time\n",
      "98 time\n",
      "99 time\n",
      "100 time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [15:11<15:54, 190.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 episode\n",
      "1 time\n",
      "2 time\n",
      "3 time\n",
      "4 time\n",
      "5 time\n",
      "6 time\n",
      "7 time\n",
      "8 time\n",
      "9 time\n",
      "10 time\n",
      "11 time\n",
      "12 time\n",
      "13 time\n",
      "14 time\n",
      "15 time\n",
      "16 time\n",
      "17 time\n",
      "18 time\n",
      "19 time\n",
      "20 time\n",
      "21 time\n",
      "22 time\n",
      "23 time\n",
      "24 time\n",
      "25 time\n",
      "26 time\n",
      "27 time\n",
      "28 time\n",
      "29 time\n",
      "30 time\n",
      "31 time\n",
      "32 time\n",
      "33 time\n",
      "34 time\n",
      "35 time\n",
      "36 time\n",
      "37 time\n",
      "38 time\n",
      "39 time\n",
      "40 time\n",
      "41 time\n",
      "42 time\n",
      "43 time\n",
      "44 time\n",
      "45 time\n",
      "46 time\n",
      "47 time\n",
      "48 time\n",
      "49 time\n",
      "50 time\n",
      "51 time\n",
      "52 time\n",
      "53 time\n",
      "54 time\n",
      "55 time\n",
      "56 time\n",
      "57 time\n",
      "58 time\n",
      "59 time\n",
      "60 time\n",
      "61 time\n",
      "62 time\n",
      "63 time\n",
      "64 time\n",
      "65 time\n",
      "66 time\n",
      "67 time\n",
      "68 time\n",
      "69 time\n",
      "70 time\n",
      "71 time\n",
      "72 time\n",
      "73 time\n",
      "74 time\n",
      "75 time\n",
      "76 time\n",
      "77 time\n",
      "78 time\n",
      "79 time\n",
      "80 time\n",
      "81 time\n",
      "82 time\n",
      "83 time\n",
      "84 time\n",
      "85 time\n",
      "86 time\n",
      "87 time\n",
      "88 time\n",
      "89 time\n",
      "90 time\n",
      "91 time\n",
      "92 time\n",
      "93 time\n",
      "94 time\n",
      "95 time\n",
      "96 time\n",
      "97 time\n",
      "98 time\n",
      "99 time\n",
      "100 time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [18:13<12:32, 188.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 episode\n",
      "1 time\n",
      "2 time\n",
      "3 time\n",
      "4 time\n",
      "5 time\n",
      "6 time\n",
      "7 time\n",
      "8 time\n",
      "9 time\n",
      "10 time\n",
      "11 time\n",
      "12 time\n",
      "13 time\n",
      "14 time\n",
      "15 time\n",
      "16 time\n",
      "17 time\n",
      "18 time\n",
      "19 time\n",
      "20 time\n",
      "21 time\n",
      "22 time\n",
      "23 time\n",
      "24 time\n",
      "25 time\n",
      "26 time\n",
      "27 time\n",
      "28 time\n",
      "29 time\n",
      "30 time\n",
      "31 time\n",
      "32 time\n",
      "33 time\n",
      "34 time\n",
      "35 time\n",
      "36 time\n",
      "37 time\n",
      "38 time\n",
      "39 time\n",
      "40 time\n",
      "41 time\n",
      "42 time\n",
      "43 time\n",
      "44 time\n",
      "45 time\n",
      "46 time\n",
      "47 time\n",
      "48 time\n",
      "49 time\n",
      "50 time\n",
      "51 time\n",
      "52 time\n",
      "53 time\n",
      "54 time\n",
      "55 time\n",
      "56 time\n",
      "57 time\n",
      "58 time\n",
      "59 time\n",
      "60 time\n",
      "61 time\n",
      "62 time\n",
      "63 time\n",
      "64 time\n",
      "65 time\n",
      "66 time\n",
      "67 time\n",
      "68 time\n",
      "69 time\n",
      "70 time\n",
      "71 time\n",
      "72 time\n",
      "73 time\n",
      "74 time\n",
      "75 time\n",
      "76 time\n",
      "77 time\n",
      "78 time\n",
      "79 time\n",
      "80 time\n",
      "81 time\n",
      "82 time\n",
      "83 time\n",
      "84 time\n",
      "85 time\n",
      "86 time\n",
      "87 time\n",
      "88 time\n",
      "89 time\n",
      "90 time\n",
      "91 time\n",
      "92 time\n",
      "93 time\n",
      "94 time\n",
      "95 time\n",
      "96 time\n",
      "97 time\n",
      "98 time\n",
      "99 time\n",
      "100 time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [21:26<09:28, 189.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 episode\n",
      "1 time\n",
      "2 time\n",
      "3 time\n",
      "4 time\n",
      "5 time\n",
      "6 time\n",
      "7 time\n",
      "8 time\n",
      "9 time\n",
      "10 time\n",
      "11 time\n",
      "12 time\n",
      "13 time\n",
      "14 time\n",
      "15 time\n",
      "16 time\n",
      "17 time\n",
      "18 time\n",
      "19 time\n",
      "20 time\n",
      "21 time\n",
      "22 time\n",
      "23 time\n",
      "24 time\n",
      "25 time\n",
      "26 time\n",
      "27 time\n",
      "28 time\n",
      "29 time\n",
      "30 time\n",
      "31 time\n",
      "32 time\n",
      "33 time\n",
      "34 time\n",
      "35 time\n",
      "36 time\n",
      "37 time\n",
      "38 time\n",
      "39 time\n",
      "40 time\n",
      "41 time\n",
      "42 time\n",
      "43 time\n",
      "44 time\n",
      "45 time\n",
      "46 time\n",
      "47 time\n",
      "48 time\n",
      "49 time\n",
      "50 time\n",
      "51 time\n",
      "52 time\n",
      "53 time\n",
      "54 time\n",
      "55 time\n",
      "56 time\n",
      "57 time\n",
      "58 time\n",
      "59 time\n",
      "60 time\n",
      "61 time\n",
      "62 time\n",
      "63 time\n",
      "64 time\n",
      "65 time\n",
      "66 time\n",
      "67 time\n",
      "68 time\n",
      "69 time\n",
      "70 time\n",
      "71 time\n",
      "72 time\n",
      "73 time\n",
      "74 time\n",
      "75 time\n",
      "76 time\n",
      "77 time\n",
      "78 time\n",
      "79 time\n",
      "80 time\n",
      "81 time\n",
      "82 time\n",
      "83 time\n",
      "84 time\n",
      "85 time\n",
      "86 time\n",
      "87 time\n",
      "88 time\n",
      "89 time\n",
      "90 time\n",
      "91 time\n",
      "92 time\n",
      "93 time\n",
      "94 time\n",
      "95 time\n",
      "96 time\n",
      "97 time\n",
      "98 time\n",
      "99 time\n",
      "100 time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [24:50<06:28, 194.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 episode\n",
      "1 time\n",
      "2 time\n",
      "3 time\n",
      "4 time\n",
      "5 time\n",
      "6 time\n",
      "7 time\n",
      "8 time\n",
      "9 time\n",
      "10 time\n",
      "11 time\n",
      "12 time\n",
      "13 time\n",
      "14 time\n",
      "15 time\n",
      "16 time\n",
      "17 time\n",
      "18 time\n",
      "19 time\n",
      "20 time\n",
      "21 time\n",
      "22 time\n",
      "23 time\n",
      "24 time\n",
      "25 time\n",
      "26 time\n",
      "27 time\n",
      "28 time\n",
      "29 time\n",
      "30 time\n",
      "31 time\n",
      "32 time\n",
      "33 time\n",
      "34 time\n",
      "35 time\n",
      "36 time\n",
      "37 time\n",
      "38 time\n",
      "39 time\n",
      "40 time\n",
      "41 time\n",
      "42 time\n",
      "43 time\n",
      "44 time\n",
      "45 time\n",
      "46 time\n",
      "47 time\n",
      "48 time\n",
      "49 time\n",
      "50 time\n",
      "51 time\n",
      "52 time\n",
      "53 time\n",
      "54 time\n",
      "55 time\n",
      "56 time\n",
      "57 time\n",
      "58 time\n",
      "59 time\n",
      "60 time\n",
      "61 time\n",
      "62 time\n",
      "63 time\n",
      "64 time\n",
      "65 time\n",
      "66 time\n",
      "67 time\n",
      "68 time\n",
      "69 time\n",
      "70 time\n",
      "71 time\n",
      "72 time\n",
      "73 time\n",
      "74 time\n",
      "75 time\n",
      "76 time\n",
      "77 time\n",
      "78 time\n",
      "79 time\n",
      "80 time\n",
      "81 time\n",
      "82 time\n",
      "83 time\n",
      "84 time\n",
      "85 time\n",
      "86 time\n",
      "87 time\n",
      "88 time\n",
      "89 time\n",
      "90 time\n",
      "91 time\n",
      "92 time\n",
      "93 time\n",
      "94 time\n",
      "95 time\n",
      "96 time\n",
      "97 time\n",
      "98 time\n",
      "99 time\n",
      "100 time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [28:04<03:14, 194.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 episode\n",
      "1 time\n",
      "2 time\n",
      "3 time\n",
      "4 time\n",
      "5 time\n",
      "6 time\n",
      "7 time\n",
      "8 time\n",
      "9 time\n",
      "10 time\n",
      "11 time\n",
      "12 time\n",
      "13 time\n",
      "14 time\n",
      "15 time\n",
      "16 time\n",
      "17 time\n",
      "18 time\n",
      "19 time\n",
      "20 time\n",
      "21 time\n",
      "22 time\n",
      "23 time\n",
      "24 time\n",
      "25 time\n",
      "26 time\n",
      "27 time\n",
      "28 time\n",
      "29 time\n",
      "30 time\n",
      "31 time\n",
      "32 time\n",
      "33 time\n",
      "34 time\n",
      "35 time\n",
      "36 time\n",
      "37 time\n",
      "38 time\n",
      "39 time\n",
      "40 time\n",
      "41 time\n",
      "42 time\n",
      "43 time\n",
      "44 time\n",
      "45 time\n",
      "46 time\n",
      "47 time\n",
      "48 time\n",
      "49 time\n",
      "50 time\n",
      "51 time\n",
      "52 time\n",
      "53 time\n",
      "54 time\n",
      "55 time\n",
      "56 time\n",
      "57 time\n",
      "58 time\n",
      "59 time\n",
      "60 time\n",
      "61 time\n",
      "62 time\n",
      "63 time\n",
      "64 time\n",
      "65 time\n",
      "66 time\n",
      "67 time\n",
      "68 time\n",
      "69 time\n",
      "70 time\n",
      "71 time\n",
      "72 time\n",
      "73 time\n",
      "74 time\n",
      "75 time\n",
      "76 time\n",
      "77 time\n",
      "78 time\n",
      "79 time\n",
      "80 time\n",
      "81 time\n",
      "82 time\n",
      "83 time\n",
      "84 time\n",
      "85 time\n",
      "86 time\n",
      "87 time\n",
      "88 time\n",
      "89 time\n",
      "90 time\n",
      "91 time\n",
      "92 time\n",
      "93 time\n",
      "94 time\n",
      "95 time\n",
      "96 time\n",
      "97 time\n",
      "98 time\n",
      "99 time\n",
      "100 time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [31:20<00:00, 188.02s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'H2Y2' object has no attribute 'scores_window'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30104\\24775642.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mh2y2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mH2Y2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mh2y2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdqn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30104\\2481159708.py\u001b[0m in \u001b[0;36mdqn\u001b[1;34m(self, n_episodes, max_t, eps_end, eps_decay)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# model save\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain_network\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'./model/CNN_LSTM_WEIGHTS.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_window\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'H2Y2' object has no attribute 'scores_window'"
     ]
    }
   ],
   "source": [
    "h2y2 = H2Y2()\n",
    "\n",
    "h2y2.dqn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[70.76023391812853,\n",
       " 85.90058479532159,\n",
       " 66.69590643274842,\n",
       " 76.54970760233908,\n",
       " 77.54385964912272,\n",
       " 72.80116959064314,\n",
       " 67.22222222222209,\n",
       " 79.69590643274849,\n",
       " 70.34502923976595,\n",
       " 75.35672514619874]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2y2.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23112\\1739732496.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# 실험해보면 좋을 것\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23112\\1739732496.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mH2Y2_env\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mH2Y2_Agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23112\\882644641.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0minit_hp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_hp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23112\\882644641.py\u001b[0m in \u001b[0;36mmake_state\u001b[1;34m(self, cur_comb)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mcomb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomb_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_bound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameter_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_comb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple_comb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtuple_comb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;31m# print(state)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "def main():\n",
    "    env = H2Y2_env()\n",
    "    agent = H2Y2_Agent()\n",
    "    state = env.reset()\n",
    "    print(len(state))\n",
    "    next_state, reward, done = env.step(state, 48)\n",
    "    print(reward)\n",
    "    print(done)\n",
    "    \n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()\n",
    "    \n",
    "# 실험해보면 좋을 것\n",
    "# 1. 다음달에 새로운 데이터가 추가되었을 때도 잘 동작하는가 ( 데이터가 점진적으로 추가되었을 때 사용이 가능한가 )\n",
    "# 2. 그리드서치, 랜덤서치, 베이지안 서치랑 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian optimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.16 ('h2y2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53e991c9edeba9e61f5fc5dc21b635cf9d5ecc55b271a0f82c627d18cdfb2087"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
